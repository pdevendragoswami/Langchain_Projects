{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07e2dc7d",
   "metadata": {},
   "source": [
    "Hybrid Search Langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e8f6e40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f20b56c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = os.getenv(\"PINECODE_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a85b6347",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.retrievers import PineconeHybridSearchRetriever\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "\n",
    "index_name = \"hybrid-search-langchain-pinecone\"\n",
    "\n",
    "# initialize the Pinecone client\n",
    "pc = Pinecone(api_key=api_key)\n",
    "\n",
    "if index_name not in pc.list_indexes().names():\n",
    "    pc.create_index(\n",
    "        name=index_name,\n",
    "        dimension=384,   # dimension of dense vector\n",
    "        metric= \"dotproduct\",  # sparse values supported only for the dotproduct\n",
    "        spec = ServerlessSpec(cloud=\"aws\",region=\"us-east-1\")\n",
    "\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1920263d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/devendra/Desktop/Udemy_Generative_AI_With_Langchain_and_Huggingface_2024/Project/Langchain_Projects/venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pinecone.db_data.index.Index at 0x77e8b0277220>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = pc.Index(index_name)\n",
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b2ef680",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/devendra/Desktop/Udemy_Generative_AI_With_Langchain_and_Huggingface_2024/Project/Langchain_Projects/venv/lib/python3.10/site-packages/torch/cuda/__init__.py:182: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at /pytorch/c10/cuda/CUDAFunctions.cpp:109.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2', cache_folder=None, model_kwargs={}, encode_kwargs={}, query_encode_kwargs={}, multi_process=False, show_progress=False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vector embedding and sparse matrix\n",
    "\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "os.environ[\"HF_TOKEN\"] = os.getenv(\"HF_TOKEN\")\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30c5ae3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pinecone_text.sparse.bm25_encoder.BM25Encoder at 0x77e8a049ba30>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pinecone_text.sparse import BM25Encoder    # BM25Encoder uses TF-IDF technique for sparse matrixs conversartion\n",
    "\n",
    "bm25_encoder = BM25Encoder.default()   #default is TF-IDF\n",
    "bm25_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69a261fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 142.11it/s]\n"
     ]
    }
   ],
   "source": [
    "sentences = [\n",
    "    \"In 2023, I visited Paris\",\n",
    "    \"In 2022, I visited New York \",\n",
    "    \"In 2021, I visited New Delhi\"\n",
    "]\n",
    "\n",
    "\n",
    "#applying  tfidf values in these sentences\n",
    "bm25_encoder.fit(sentences)\n",
    "\n",
    "#store the values to a json file\n",
    "bm25_encoder.dump(\"bm25_values.json\")\n",
    "\n",
    "\n",
    "#load to em25encoder object\n",
    "bm25_encoder = BM25Encoder().load(\"bm25_values.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f7e3633b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PineconeHybridSearchRetriever(embeddings=HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2', cache_folder=None, model_kwargs={}, encode_kwargs={}, query_encode_kwargs={}, multi_process=False, show_progress=False), sparse_encoder=<pinecone_text.sparse.bm25_encoder.BM25Encoder object at 0x77e8b0276680>, index=<pinecone.db_data.index.Index object at 0x77e8b0277220>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create retriever\n",
    "\n",
    "retriever = PineconeHybridSearchRetriever(embeddings=embeddings, sparse_encoder=bm25_encoder,index=index)\n",
    "retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b1ded45d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.28s/it]\n"
     ]
    }
   ],
   "source": [
    "retriever.add_texts(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2c842483",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'score': 0.270836}, page_content='In 2022, I visited New York '),\n",
       " Document(metadata={'score': 0.250163287}, page_content='In 2023, I visited Paris'),\n",
       " Document(metadata={'score': 0.236216679}, page_content='In 2021, I visited New Delhi')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.invoke(\"What city did i visited last?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2823f661",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'score': 0.643733144}, page_content='In 2021, I visited New Delhi'),\n",
       " Document(metadata={'score': 0.327555031}, page_content='In 2022, I visited New York '),\n",
       " Document(metadata={'score': 0.237566143}, page_content='In 2023, I visited Paris')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.invoke(\"When i visited New Delhi?\") "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
